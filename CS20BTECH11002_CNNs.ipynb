{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(precision=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Loading Images Data***\\\n",
    "Change the file name varibale to the path where the CIFAR-10 images data_batch_1 is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo,encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "file = \"./cifar-10-python/cifar-10-batches-py/data_batch_1\"\n",
    "dict = unpickle(file)\n",
    "\n",
    "Keys = list(dict.keys())\n",
    "Images_original = dict[Keys[2]]\n",
    "Labels = dict[Keys[1]]\n",
    "Images = []\n",
    "Images_list = [[] for i in range(10)]\n",
    "\n",
    "for index,i in enumerate(Images_original):\n",
    "    tensor = torch.tensor(i.reshape(3,32,32))\n",
    "    tensor = tensor.type(torch.FloatTensor)\n",
    "    tensor = tensor/255\n",
    "    Images.append(tensor)\n",
    "    Images_list[Labels[index]].append(tensor)\n",
    "\n",
    "\n",
    "# plt.imshow(Images[4].permute(1, 2, 0), interpolation='nearest')\n",
    "\n",
    "#Dividing the images into their respective Classes\n",
    "\n",
    "# plt.imshow(Images_original[2].reshape(3,32,32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***List of our Activation Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_func(x):\n",
    "    return torch.exp(x)/(1 + torch.exp(x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return torch.maximum(torch.zeros(x.shape),x)\n",
    "\n",
    "\n",
    "def ParaReLU(x,alpha = 0.01):\n",
    "    return torch.maximum(torch.zeros(x.shape),x) + alpha*torch.minimum(torch.zeros(x.shape),x)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x) - torch.exp(-x))/(torch.exp(x) + torch.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 1***\\\n",
    "Here we write our convulution function which takes input image as a tensor, kernel, padding, stride, and \\\n",
    "activation function.\\\n",
    "Note that since we are providing only one filter the output will be single channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convulution_function(input_tensor,kernel,padding=(0,0),stride=(1,1),activation_func = sigmoid_func):\n",
    "    #First we pad the tensor\n",
    "    #input tensor  : C * H * W\n",
    "    Shape = input_tensor.shape\n",
    "    C = Shape[0]\n",
    "    H = Shape[1]\n",
    "    W = Shape[2]\n",
    "\n",
    "    ker_shape = kernel.shape\n",
    "    kernel_size = (ker_shape[1],ker_shape[2])\n",
    "\n",
    "    #Adding coloumns to tensor\n",
    "    col_zero_tensor = torch.zeros((C,H,padding[1]))\n",
    "    final_tens = torch.cat((input_tensor,col_zero_tensor),-1)\n",
    "    final_tens = torch.cat((col_zero_tensor, final_tens),-1)\n",
    "\n",
    "    #Size of the tensor changes now\n",
    "    W = W + 2*padding[1]\n",
    "\n",
    "    #Adding rows to the tensor\n",
    "    row_zero_tensor = torch.zeros((C,padding[0],W))\n",
    "    final_tens = torch.cat((final_tens, row_zero_tensor),1)\n",
    "    final_tens = torch.cat((row_zero_tensor,final_tens),1)\n",
    "\n",
    "    #Now the shape of our tensor changes\n",
    "    Shape = final_tens.shape\n",
    "    C = Shape[0]\n",
    "    H = Shape[1]\n",
    "    W = Shape[2]\n",
    "\n",
    "\n",
    "    #Now we convolve using kernels\n",
    "\n",
    "    #Defining our output tensor\n",
    "    H_fin = math.floor(((H - kernel_size[0])/stride[0]) + 1)\n",
    "    W_fin = math.floor(((W - kernel_size[1])/stride[1]) + 1)\n",
    "    Final_tensor = torch.rand(1,H_fin,W_fin)\n",
    "    Final_tensor = Final_tensor.type(torch.FloatTensor)\n",
    "\n",
    "    #Main convolving Loop\n",
    "    i1 = 0\n",
    "    for i in range(0, H-kernel_size[0]+1, stride[0]):\n",
    "        j1 = 0\n",
    "        for j in range(0,W-kernel_size[1]+1,stride[1]):\n",
    "                dummy = torch.zeros((C,kernel_size[0],kernel_size[1]))\n",
    "                dummy = final_tens[:C+1,i:i+kernel_size[0],j:j+kernel_size[1]]\n",
    "                sum = torch.mul(dummy,kernel).sum()\n",
    "                Final_tensor[0][i1][j1] = sum\n",
    "                j1 = j1 + 1\n",
    "        i1 = i1 + 1\n",
    "    \n",
    "    return activation_func(Final_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing outputs for various activation functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_activation_map = torch.tensor([[-1,-2,-3],[4,-5,6],[-7,8,9]]).reshape(1,3,3)\n",
    "kernel = torch.rand(1,2,2)\n",
    "padding = (0,0)\n",
    "stride = (1,1)\n",
    "\n",
    "#printing outputs with various activation funcs\n",
    "print(\"Sigmoid activation = \")\n",
    "print(convulution_function(input_activation_map,kernel,padding,stride,sigmoid_func))\n",
    "\n",
    "print(\"ReLU activation = \")\n",
    "print(convulution_function(input_activation_map,kernel,padding,stride,ReLU))\n",
    "\n",
    "print(\"Parametric Relu activation = \")\n",
    "print(convulution_function(input_activation_map,kernel,padding,stride,ParaReLU))\n",
    "\n",
    "print(\"tanh activation = \")\n",
    "print(convulution_function(input_activation_map,kernel,padding,stride,tanh))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing output for Question1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_activation_map = Images[0]\n",
    "kernel = torch.rand(3,3,3,) #Kernel of size 3*3 the first 3 is for number of channels.\n",
    "padding = (0,0)\n",
    "stride = (1,1)\n",
    "activation_func = sigmoid_func\n",
    "output_activation_map = convulution_function(input_activation_map,kernel,padding,stride,activation_func)\n",
    "\n",
    "#Displaying Results\n",
    "print(\"Input Image =\")\n",
    "plt.imshow(Images[0].permute(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "print(\"Filter kernel =\")\n",
    "print(kernel)\n",
    "\n",
    "\n",
    "print(\"Output Activation Map=\")\n",
    "print(output_activation_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question2***\\\n",
    "Here we define our Pooling functions and our Pooling function which performs the actual pooling.\n",
    "The pooling function accepts output of the convulution function,stride,pooling function and kernel size.\\\n",
    "Since output of convulution function is bsingle channel output of pooling function is also single channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining our pooling functions\n",
    "\n",
    "def max_pool(x):\n",
    "    return torch.max(x)\n",
    "\n",
    "def avg_pool(x):\n",
    "    return x.sum()/(x.size(1) * x.size(0) * x.size(2))\n",
    "\n",
    "def global_avg_pool(x):\n",
    "    stride = [0,0]\n",
    "    shape = x.shape\n",
    "    stride[0] = shape[1]\n",
    "    stride[1] = shape[2]\n",
    "    return stride\n",
    "\n",
    "def Pooling(input_tensor, stride, pooling_func = global_avg_pool,pool_size = []):\n",
    "    if pool_size == []:\n",
    "        pool_size = [stride[0],stride[1]]\n",
    "    Shape = input_tensor.shape\n",
    "    C = Shape[0]\n",
    "    H = Shape[1]\n",
    "    W = Shape[2]\n",
    "    H_fin = math.floor(((H - pool_size[0])/stride[0]) + 1)\n",
    "    W_fin = math.floor(((W - pool_size[1])/stride[1]) + 1)\n",
    "    Final_tensor = torch.rand(1,H_fin,W_fin)\n",
    "\n",
    "\n",
    "    i1 = 0\n",
    "    for i in range(0, H-pool_size[0]+1, stride[0]):\n",
    "        j1 = 0\n",
    "        for j in range(0,W-pool_size[1]+1,stride[1]):\n",
    "                dummy = torch.zeros((C,pool_size[0],pool_size[1]))\n",
    "                dummy = input_tensor[:C+1,i:i+pool_size[0],j:j+pool_size[1]]\n",
    "                sum = pooling_func(dummy)\n",
    "                Final_tensor[0][i1][j1] = sum\n",
    "                j1 = j1 + 1\n",
    "        i1 = i1 + 1\n",
    "\n",
    "    return Final_tensor  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing Outputs for Question2***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pool = output_activation_map #Input for pooling is output from previous function\n",
    "stride = (3,3)\n",
    "kernel_size = (2,2)\n",
    "pooling_func = max_pool\n",
    "output_pool = Pooling(input_pool,stride,pooling_func,kernel_size)\n",
    "\n",
    "#Printing the required values\n",
    "print(\"Input activation map= \")\n",
    "print(input_pool)\n",
    "\n",
    "print(\"output activation map=\")\n",
    "print(output_pool)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question3***\\\n",
    " Here we write our convulution layer function which takes input image as a tensor,number of fiters, kernel_size, padding, stride, and \\\n",
    "activation function,(optional kernels as well).\\\n",
    "Number of channels in the output will be number of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolution_Layer_Function(input_tensor,number_filters,kernel_size,padding=(0,0),stride=(1,1),activation_func=sigmoid_func,kernels = []):\n",
    "    #Shape of our input_tensor\n",
    "    Shape = input_tensor.shape\n",
    "    C = Shape[0]\n",
    "    H = Shape[1]\n",
    "    W = Shape[2]\n",
    "\n",
    "    #Defining our kernels\n",
    "    if kernels == []:\n",
    "        kernels = torch.rand(number_filters,C,kernel_size[0], kernel_size[1])\n",
    "    \n",
    "    for i in range(number_filters):\n",
    "        if i == 0:\n",
    "            final_tensor = convulution_function(input_tensor,kernels[i],padding,stride,activation_func)\n",
    "        else:\n",
    "            temp_tensor = convulution_function(input_tensor,kernels[i],padding,stride,activation_func)\n",
    "            final_tensor = torch.cat((final_tensor,temp_tensor))\n",
    "    return final_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing Output for Question3***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_activation_map = Images[0]\n",
    "number_filters = 8\n",
    "kernel_size = (3,3)\n",
    "kernel = torch.rand(8,input_activation_map.shape[0],3,3)/500\n",
    "stride = (1,1)\n",
    "padding = (0,0)\n",
    "activation_func = sigmoid_func\n",
    "output_activation_map = Convolution_Layer_Function(input_activation_map,number_filters,kernel_size,padding,stride,activation_func,kernel)\n",
    "#printing the values\n",
    "print(\"Input activation map = \")\n",
    "print(input_activation_map)\n",
    "\n",
    "print(\"Filter kernels=\")\n",
    "print(kernel)\n",
    "\n",
    "print(\"Output activation map = \")\n",
    "print(output_activation_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verifying the size of the output and input.***\\\n",
    "Here we are taking number of filters = 8 and kernel_size = (3,3)\\\n",
    "size of image = 3 x 32 x 32\\\n",
    "since padding = (0,0) and stride = (1,1)\\\n",
    "expected height of output = 32 - 3 + 1= 30\\\n",
    "expected width of output = 32 - 3 + 1 = 30 \\\n",
    "Number of channels of output = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying Size\n",
    "print(\"expected channel size of output=\",number_filters)\n",
    "expected_height = math.floor(((input_activation_map.shape[1] - kernel_size[0] + 2*padding[0])/stride[0]) + 1)\n",
    "print(\"expected height of output = \",expected_height)\n",
    "expected_width = math.floor(((input_activation_map.shape[2] - kernel_size[1] + 2*padding[1])/stride[1]) + 1)\n",
    "print(\"expected width of output = \",expected_width)\n",
    "\n",
    "\n",
    "print(\"channel size of output=\",output_activation_map.shape[0])\n",
    "print(\"height of output = \",output_activation_map.shape[1])\n",
    "print(\"width of output = \",output_activation_map.shape[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 4***\\\n",
    "Accepts an input tensor, stride, pooling function and pool_size. For Global Average Pooling just input tensor and\\\n",
    " pool_func (global_avg_pool in our case are enough). Since we do not change the number of channels in case of pooling the number of channels in the input and in the output remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pooling_Layer_Function(input_tensor,stride = [],pool_func = global_avg_pool,pool_size = []):\n",
    "    if stride == []:\n",
    "        stride = [input_tensor.shape[1],input_tensor.shape[2]]\n",
    "    if pool_size == []:\n",
    "        pool_size = [stride[0],stride[1]]\n",
    "    Shape = input_tensor.shape\n",
    "    C = Shape[0]\n",
    "    H = Shape[1]\n",
    "    W = Shape[2]\n",
    "\n",
    "    if(pool_func == global_avg_pool):\n",
    "        pool_size = global_avg_pool(input_tensor)\n",
    "        pool_func = avg_pool\n",
    "\n",
    "    H_fin = math.floor(((H - pool_size[0])/stride[0]) + 1)\n",
    "    W_fin = math.floor(((W - pool_size[1])/stride[1]) + 1)\n",
    "    Final_tensor = torch.rand(C,H_fin,W_fin)\n",
    "\n",
    "    for c in range(C):\n",
    "        Final_tensor[c] = Pooling(input_tensor[c].reshape(1,H,W),pool_size,pool_func)\n",
    "\n",
    "    return Final_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing values for Question4***\\\n",
    "Let us take the output of question 3 as our input with stride = 2 and kernel size =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pool = output_activation_map\n",
    "kernel_size = (2,2)\n",
    "stride = (2,2)\n",
    "pool_func = max_pool\n",
    "output_pool = Pooling_Layer_Function(input_pool,stride,max_pool,kernel_size)\n",
    "\n",
    "#Printing the values\n",
    "print(\"Input map = \")\n",
    "print(input_pool)\n",
    "\n",
    "print(\"Output map = \")\n",
    "print(output_pool)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verification of Global Average Pooling Layer***\\\n",
    "Take input tensor =[[1,2],[3,4]]\\\n",
    "Then by applying global average pooling we need to get a single element tensor with 2.5 as answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1,2],[3,4]]).reshape(1,2,2)\n",
    "output_tensor = Pooling_Layer_Function(input_tensor,pool_func = global_avg_pool)\n",
    "\n",
    "print(output_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 5***\\\n",
    "Takes input an activation map and prints out a vector of specified size by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Flatenning(input_tensor,output_size,W=[]):\n",
    "    input_tensor  = input_tensor.reshape(-1)\n",
    "    input_tensor = input_tensor.type(torch.FloatTensor)\n",
    "    if W == []:\n",
    "        W = torch.rand(input_tensor.size(0),output_size)/500\n",
    "\n",
    "    final = torch.t(W) @ input_tensor\n",
    "\n",
    "    return final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing output for Question5***\\\n",
    "Let us take output of the previous question as our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_flatenning = output_pool\n",
    "output_size = 10\n",
    "output_flatenning = Flatenning(input_flatenning,output_size)\n",
    "\n",
    "#Printing the outputs\n",
    "print(\"Output vector = \")\n",
    "print(output_flatenning)\n",
    "\n",
    "print(\"input activation map = \")\n",
    "print(input_flatenning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 6***\\\n",
    "First we define the softmax function and the MLP Layer function the MLP function accepts an input vector, number of hidden layers\\\n",
    "sizes of hidden layers, output_size and activation func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = torch.exp(x)\n",
    "    x = x/(x.sum())\n",
    "    return x\n",
    "\n",
    "\n",
    "def MLP(input_tensor, number_hidden_layers,hidden_layer_sizes,output_size,activation_func,Weights = []):\n",
    "    total_layers = []\n",
    "    total_layers.append(input_tensor.size(0))\n",
    "    for a in hidden_layer_sizes:\n",
    "        total_layers.append(a)\n",
    "    total_layers.append(output_size)\n",
    "\n",
    "    total_no_weights = number_hidden_layers + 1\n",
    "\n",
    "    if Weights == []:\n",
    "        for i in range(total_no_weights):\n",
    "            weight = torch.rand(total_layers[i],total_layers[i+1])\n",
    "            Weights.append(weight)\n",
    "\n",
    "    final_tensor = input_tensor\n",
    "\n",
    "    for j in range(total_no_weights-1):\n",
    "        final_tensor = final_tensor.type(torch.FloatTensor)\n",
    "        final_tensor = activation_func(torch.t(Weights[j]) @ final_tensor)\n",
    "\n",
    "    final_tensor = final_tensor.type(torch.FloatTensor)\n",
    "    final_tensor = torch.t(Weights[-1]) @ final_tensor\n",
    "    \n",
    "    return softmax(final_tensor),final_tensor\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing the outputs of Question6***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take the input vector as output of the previous question\n",
    "input_vector = output_flatenning\n",
    "number_hidden_layers = 4\n",
    "hidden_layer_sizes = [4,6,8,10]\n",
    "output_size  = 10\n",
    "activation_func = sigmoid_func\n",
    "output_softmax, output_nosoft = MLP(input_vector,number_hidden_layers,hidden_layer_sizes,output_size,activation_func)\n",
    "\n",
    "#Printing values\n",
    "print(\"Output with no softmax = \")\n",
    "print(output_nosoft)\n",
    "\n",
    "print(\"Output with softmax = \")\n",
    "print(output_softmax)\n",
    "\n",
    "print(\"Sum of elements in the final tensor with softmax = \")\n",
    "print(output_softmax.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question7***\\\n",
    "Here we write a class for our CNN Architecture with feed forward method which will perform the actual feed forwards\\\n",
    "The output of this method will be the final tensor with the softmax applied.\\\n",
    "Our model while initialization takes input the number of input channels and size of output vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Arch:\n",
    "    Weights = []\n",
    "    Final_output = None\n",
    "    Input_channels = None    \n",
    "    Output_channels = None\n",
    "\n",
    "    def __init__(self,input_channels,output_channels):\n",
    "        #Filling our variables\n",
    "        self.Input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "\n",
    "        #Kernels for 1st CNN layer\n",
    "        Kernel = torch.rand(16,input_channels,3,3)/100\n",
    "        self.Weights.append(Kernel)\n",
    "\n",
    "        #Kernels for 2nd CNN layer\n",
    "        Kernel2 = torch.rand(8,16,3,3)/100\n",
    "        self.Weights.append(Kernel2)\n",
    "\n",
    "        #Weights for flattenning\n",
    "        weight3 = torch.rand(8,8)\n",
    "        self.Weights.append(weight3)\n",
    "\n",
    "        #Weights for MLP Layer\n",
    "        weight1 = torch.rand(8,8)\n",
    "        self.Weights.append(weight1)\n",
    "\n",
    "        weight2 = torch.rand(8,output_channels)\n",
    "        self.Weights.append(weight2)\n",
    "    \n",
    "    def feed_forward(self,input_image):\n",
    "        #1st convolution layer\n",
    "        final_output = Convolution_Layer_Function(input_image,16,(3,3),(0,0),(1,1),sigmoid_func,self.Weights[0])\n",
    "\n",
    "        #1st pooling layer\n",
    "        final_output = Pooling_Layer_Function(final_output,(2,2),max_pool)\n",
    "\n",
    "        #2nd covolution layer\n",
    "        final_output = Convolution_Layer_Function(final_output,8,(3,3),(0,0),(1,1),sigmoid_func,self.Weights[1])\n",
    "\n",
    "        #2nd Pooling Layer\n",
    "        final_output = Pooling_Layer_Function(final_output,(2,2),max_pool)\n",
    "\n",
    "        #Global Average Pooling Layer\n",
    "        final_output = Pooling_Layer_Function(final_output,(1,1),global_avg_pool)\n",
    "\n",
    "        #Flatenning the input\n",
    "        final_output = Flatenning(final_output,8,self.Weights[2])\n",
    "        flatenning_output = final_output\n",
    "        #Passing to MLP\n",
    "        final_output,final_output_nosoft = MLP(final_output,1,[final_output.size(0)],10,sigmoid_func,[self.Weights[3],self.Weights[4]])\n",
    "        # print(final_output)\n",
    "\n",
    "        return final_output,flatenning_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Printing Outputs for Question7***\\\n",
    "Verifying the input and output sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Images[0]\n",
    "input_channels = input_image.shape[0]\n",
    "output_size = 10\n",
    "model = CNN_Arch(input_channels,output_size)\n",
    "output,flatenning_output = model.feed_forward(input_image)\n",
    "\n",
    "#Printing output\n",
    "print(\"Shape of input image tensor = \",input_image.shape)\n",
    "\n",
    "\n",
    "print(\"Output = \")\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 8a***\\\n",
    "Printing output from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model takes in the input number of input channels and size of output layer\n",
    "model = CNN_Arch(3,10)\n",
    "\n",
    "for i in range(10):\n",
    "    final_output,flatenning_output = model.feed_forward(Images_list[i][0])\n",
    "    print(\"Output for class\",i,\"=\",final_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis of Question 8a***\\\n",
    "We can see that after printing the values, irrespective of the image class there is only a little diffrence in the output vectors.\\\n",
    "This is because our model is still untrained and hence outputs almost same vector for every image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question 8b***\\\n",
    "First we need to get our data of bottleneck into an array so that we can perform PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cells_PCA = []\n",
    "Labels_PCA = []\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(3):\n",
    "        final_output,bottleneck_output = model.feed_forward(Images_list[i][j])\n",
    "        Cells_PCA.append(bottleneck_output.numpy())\n",
    "        Labels_PCA.append(i)\n",
    "\n",
    "Cells_PCA = np.array(Cells_PCA)\n",
    "print(Cells_PCA.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting our data we can perform the Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Since we need to draw graph in 2-dimension n_components will be 2\n",
    "PCA_model = PCA(n_components=2)\n",
    "reduced_data = PCA_model.fit_transform(Cells_PCA)\n",
    "\n",
    "#Plotting our reduced data.\n",
    "plt.scatter(reduced_data[:,0],reduced_data[:,1], c = Labels_PCA, cmap = plt.cm.get_cmap('prism',10))\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analysis for Question 8b***\\\n",
    "As we can see after performing PCA we can see that even images of same classes are far part (i.e their bottleneck outputs are diffrent.)\\\n",
    "If they were similar then clusters of one color should have formed but this is not the case since our model is untrained and just randomly initialised.\\\n",
    "\\\n",
    "Hence we can say that a randomly initialized neural network does not show any discriminabilty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
